{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d1ad80-8c9b-4671-bc78-1173e3a7a0cf",
   "metadata": {},
   "source": [
    "# nnUNet WSI inference pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686ac38-0b48-4e04-b653-6694febda997",
   "metadata": {},
   "source": [
    "nnUNet by default does half overlap if the given patch is bigger than the model's patch size.\n",
    "This means that on the borders there is no or 1x overlap (1 or 2 predictions),\n",
    "while in the inside there are 4 predictions for each pixel. In this version of nnUNet WSI inference, we crop this border off the sampled patch, and only write the inner part.\n",
    "\n",
    "This approach becomes more efficient if bigger patches are sampled, because this increases the inner/outer ratio. \n",
    "To prevent inference on large empty patches we add a check if we can remove rows and columns, while preserving the half overlap of nnUNet's sliding window approach. \n",
    "\n",
    "Next to doing inference we also calculate the mean disagreement of the 5 folds for every output pixel, as described in the MIDL paper. \n",
    "\n",
    "The loop is constructed in such a manner that multiple scripts can run in parralel without interfering. It does so by creating a '\\<name\\>_runtime.txt'  file once the loop starts inference on a new WSI + tissue mask match. If this txt file exists it means this match has already been processed or is currently being processed. This means that if a run failed, you'll need to delete its txt file to run it again. \n",
    "\n",
    "While this is the approach we used for our TIGER performance, there is still quite some room for improvement. We are currently working on an improved version which is more readable and easier constructed. \n",
    "\n",
    "In this file we will also auto-configure the config and files yamls, which may seem quite complex but can come in handy while debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6934ae-19f4-457d-a350-b68e5091614f",
   "metadata": {},
   "source": [
    "## Download example files\n",
    "These are 2 images and 2 corresponding tissue masks\n",
    "\n",
    "##### *aws s3 cp --no-sign-request s3://tiger-training/wsibulk/images/103S.tif /add/your/path/here/wsibulk/images/103S.tif*\n",
    "\n",
    "##### *aws s3 cp --no-sign-request s3://tiger-training/wsibulk/tissue-masks/103S_tissue.tif /add/your/path/here/wsibulk/tissue-masks/103S_tissue.tif*\n",
    "\n",
    "##### *aws s3 cp --no-sign-request s3://tiger-training/wsibulk/images/111S.tif /add/your/path/here/wsibulk/images/111S.tif*\n",
    "\n",
    "##### *aws s3 cp --no-sign-request s3://tiger-training/wsibulk/tissue-masks/111S_tissue.tif /add/your/path/here/wsibulk/tissue-masks/111S_tissue.tif*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88983f3d-549b-47b9-8bd8-428586ea68cc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b866bc-04c8-4568-9f1e-06766dda1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "nnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "RESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    }
   ],
   "source": [
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "from wholeslidedata.accessories.asap.imagewriter import WholeSlideMaskWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nnunet.training.model_restore import load_model_and_checkpoint_files\n",
    "import os\n",
    "import torch\n",
    "from wholeslidedata.samplers.utils import fit_data\n",
    "import yaml\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f07a97-210c-4bf3-afd5-43b1bed9e78e",
   "metadata": {},
   "source": [
    "# Functions and utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab36d76-7599-4cda-85a5-2ebd2c215f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_01(x_batch): # Use this for models trained on 0-1 scaled data\n",
    "    x_batch = x_batch / 255\n",
    "    x_batch = x_batch.transpose(3, 0, 1, 2)\n",
    "    return x_batch\n",
    "\n",
    "def z_norm(x_batch): # use this for default nnunet models, using z-score normalized data\n",
    "    mean = x_batch.mean(axis=(-2,-1), keepdims=True)\n",
    "    std = x_batch.std(axis=(-2,-1), keepdims=True)\n",
    "    x_batch = ((x_batch - mean) / (std + 1e-8))\n",
    "    x_batch = x_batch.transpose(3, 0, 1, 2)\n",
    "    return x_batch\n",
    "\n",
    "\n",
    "def ensemble_softmax_list(trainer, params, x_batch):\n",
    "    softmax_list = []\n",
    "    for p in params:\n",
    "        trainer.load_checkpoint_ram(p, False)\n",
    "        softmax_list.append(\n",
    "            trainer.predict_preprocessed_data_return_seg_and_softmax(x_batch.astype(np.float32), verbose=False,\n",
    "                                                                     do_mirroring=False, mirror_axes=[])[\n",
    "                -1].transpose(1, 2, 3, 0).squeeze())\n",
    "    return softmax_list\n",
    "\n",
    "\n",
    "def array_to_formatted_tensor(array):\n",
    "    array = np.expand_dims(array.transpose(2, 0, 1), 0)\n",
    "    return torch.tensor(array)\n",
    "\n",
    "\n",
    "def softmax_list_and_mean_to_uncertainty(softmax_list, softmax_mean):\n",
    "    loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    uncertainty_loss_per_pixel_list = []\n",
    "    for softmax in softmax_list:\n",
    "        log_softmax = np.log(softmax + 0.00000001)\n",
    "        uncertainty_loss_per_pixel = loss(array_to_formatted_tensor(log_softmax),\n",
    "                                          array_to_formatted_tensor(softmax_mean))\n",
    "        uncertainty_loss_per_pixel_list.append(uncertainty_loss_per_pixel)\n",
    "    uncertainty = torch.cat(uncertainty_loss_per_pixel_list).mean(dim=0)\n",
    "    return uncertainty\n",
    "\n",
    "def get_trim_indexes(y_batch):\n",
    "    \"\"\"\n",
    "    Using the y_mask / tissue-background mask we can check if there are\n",
    "    full empty rows and columns with a width of half the model patch size.\n",
    "    We check this in half model patch size increments because otherwise\n",
    "    we screw up the half overlap approach from nnunet (resulting in inconsistent\n",
    "    overlap thoughout the WSI).\n",
    "    We will still need 1 row or column that is empty to make sure the parts that\n",
    "    do have tissue have 4x overlap\n",
    "    \"\"\"\n",
    "    y = y_batch[0]\n",
    "    r_is_empty = [not y[start:end].any() for start, end in zip(half_patch_size_start_idxs, half_patch_size_end_idxs)]\n",
    "    c_is_empty = [not y[:, start:end].any() for start, end in zip(half_patch_size_start_idxs, half_patch_size_end_idxs)]\n",
    "\n",
    "    empty_rs_top = 0\n",
    "    for r in r_is_empty:\n",
    "        if r == True:\n",
    "            empty_rs_top += 1  # count empty rows\n",
    "        else:\n",
    "            trim_top_half_idx = empty_rs_top - 1  # should always include a single empty row, since we need the overlap\n",
    "            trim_top_half_idx = np.clip(trim_top_half_idx, 0, None)  # cannot select regiouns outside sampled patch\n",
    "            trim_top_idx = half_patch_size_start_idxs[trim_top_half_idx]\n",
    "            break\n",
    "\n",
    "    empty_rs_bottom = 0\n",
    "    for r in r_is_empty[::-1]:\n",
    "        if r == True:\n",
    "            empty_rs_bottom += 1\n",
    "        else:\n",
    "            trim_bottom_half_idx = empty_rs_bottom - 1\n",
    "            trim_bottom_half_idx = np.clip(trim_bottom_half_idx, 0, None)\n",
    "            trim_bottom_idx = half_patch_size_end_idxs[::-1][trim_bottom_half_idx]  # reverse index\n",
    "            break\n",
    "\n",
    "    empty_cs_left = 0\n",
    "    for c in c_is_empty:\n",
    "        if c == True:\n",
    "            empty_cs_left += 1\n",
    "        else:\n",
    "            trim_left_half_idx = empty_cs_left - 1\n",
    "            trim_left_half_idx = np.clip(trim_left_half_idx, 0, None)\n",
    "            trim_left_idx = half_patch_size_start_idxs[trim_left_half_idx]\n",
    "            break\n",
    "\n",
    "    empty_cs_right = 0\n",
    "    for c in c_is_empty[::-1]:\n",
    "        if c == True:\n",
    "            empty_cs_right += 1\n",
    "        else:\n",
    "            trim_right_half_idx = empty_cs_right - 1\n",
    "            trim_right_half_idx = np.clip(trim_right_half_idx, 0, None)\n",
    "            trim_right_idx = half_patch_size_end_idxs[::-1][trim_right_half_idx]\n",
    "            break\n",
    "\n",
    "    # print(trim_top_half_idx, trim_bottom_half_idx, trim_left_half_idx, trim_right_half_idx)\n",
    "    # print(trim_top_idx, trim_bottom_idx, trim_left_idx, trim_right_idx)\n",
    "    return trim_top_idx, trim_bottom_idx, trim_left_idx, trim_right_idx\n",
    "\n",
    "\n",
    "def find_matches(img_folder, match_folder, img_extension='', match_extension='', match_contains='', exact_match=False):\n",
    "    img_files = [item for item in os.listdir(img_folder) if\n",
    "                 os.path.isfile(os.path.join(img_folder, item)) and item.endswith(img_extension)]\n",
    "\n",
    "    match_files = [item for item in os.listdir(match_folder) if os.path.isfile(os.path.join(match_folder, item))]\n",
    "\n",
    "    # Match and optional filter\n",
    "    if exact_match:\n",
    "        assert match_extension != '', 'exact_match needs a match extension to verify if img stem + match_extension == match filename'\n",
    "        img_match_paths = [(os.path.join(img_folder, img_file),  # add wsi folder in front\n",
    "                            os.path.join(match_folder, match_file))  # add xml folder in front\n",
    "                           for img_file in img_files  # loop over wsi folder files\n",
    "                           for match_file in match_files  # loop over filtered annotaion files\n",
    "                           if Path(match_file).name.startswith(\n",
    "                Path(img_file).stem)  # only return if bg file starts with img file name (without suffix)\n",
    "                           and (match_file == Path(img_file).stem + match_extension)  # exact match\n",
    "                           and match_contains in match_file]  # only return if match contains match_contains\n",
    "\n",
    "    else:\n",
    "        img_match_paths = [(os.path.join(img_folder, img_file),  # add wsi folder in front\n",
    "                            os.path.join(match_folder, match_file))  # add xml folder in front\n",
    "                           for img_file in img_files  # loop over wsi folder files\n",
    "                           for match_file in match_files  # loop over filtered annotaion files\n",
    "                           if Path(match_file).name.startswith(\n",
    "                Path(img_file).stem)  # only return if bg file starts with img file name (without suffix)\n",
    "                           and match_contains in match_file]  # only return if match contains match_contains\n",
    "\n",
    "    # Checks and prints\n",
    "    if len(img_match_paths) > 0:\n",
    "        matched_img_paths, _ = zip(*img_match_paths)\n",
    "        matched_img_files = [Path(img_path).name for img_path in matched_img_paths]\n",
    "        unmatched = [img_file for img_file in img_files if img_file not in matched_img_files]\n",
    "        matches = [img_file for img_file in matched_img_files if\n",
    "                   img_file in img_files]  # this captures multiple matches per img_file\n",
    "        if len(unmatched) > 0:\n",
    "            print(f'{len(unmatched)} files were not machted:\\n', unmatched)\n",
    "        else:\n",
    "            print('All image files were matched')\n",
    "        if len(set(matches)) < len(matches):\n",
    "            print('Some matched image files have multiple matches')\n",
    "            raise Exception('Ambiguous')\n",
    "        if len(matches) == len(set(matches)):\n",
    "            print('Each matched image file has a single match')\n",
    "    else:\n",
    "        print('No matches')\n",
    "    print('\\n')\n",
    "    return img_match_paths\n",
    "\n",
    "def make_files_yml_and_return_matches_to_run(matches, files_yml_output_path, output_folder):\n",
    "    \"\"\"\n",
    "    The whole pipeline is costructed in such a way that a <name>_runtime.txt file is created once a python script started to work on this WSI + mask match. This means that this file should not be processed anymore by another python script that is run in parralel (also doesnt need to be copied to the local machine (chis is the case on our computing cluster))\n",
    "    \"\"\"\n",
    "    runtime_stems = [file[:-12] for file in os.listdir(output_folder) if file.endswith('_runtime.txt')]\n",
    "    imgs, _ = zip(*matches)\n",
    "    img_stems = [Path(file).stem for file in imgs]\n",
    "    matches_to_run_idx = [i for i in range(len(img_stems)) if img_stems[i] not in runtime_stems]\n",
    "    matches_to_run = [matches[i] for i in matches_to_run_idx]\n",
    "    \n",
    "    yaml_file = {\"validation\": []}\n",
    "    for wsi, wsa in matches_to_run:\n",
    "        # print(wsi, wsa)\n",
    "        # 1/0\n",
    "        yaml_file[\"validation\"].append({\"wsi\": {\"path\": str(wsi)},\n",
    "                                        \"wsa\": {\"path\": str(wsa)}})\n",
    "    with open(files_yml_output_path, 'w') as f:\n",
    "        yaml.dump(yaml_file, f)\n",
    "        print('CREATED FILES YAML:', files_yml_output_path)\n",
    "\n",
    "    return matches_to_run\n",
    "\n",
    "def get_closest_spacing(spacing_value):\n",
    "    possible_spacings = [0.25, 0.5, 1, 2, 4, 8, 16]\n",
    "    closest = min(possible_spacings, key=lambda x:abs(x-spacing_value))\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499601c-68e3-4592-bcf3-231540016d95",
   "metadata": {},
   "source": [
    "# Load model\n",
    "### CHANGE YOUR MODEL AND INPUT NORMALIZATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02528047-c756-46be-853e-afbb162c9237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_model_base\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512 \n",
      "\n",
      "nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512 \n",
      "\n",
      "using the following model files:  ['example_model_base\\\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512\\\\fold_0\\\\model_best.model', 'example_model_base\\\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512\\\\fold_1\\\\model_best.model', 'example_model_base\\\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512\\\\fold_2\\\\model_best.model', 'example_model_base\\\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512\\\\fold_3\\\\model_best.model', 'example_model_base\\\\nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512\\\\fold_4\\\\model_best.model']\n"
     ]
    }
   ],
   "source": [
    "model_base_path = Path('example_model_base/nnUNetTrainerV2_BN_pathology_DA_ignore0_hed005__nnUNet_RGB_scaleTo_0_1_bs8_ps512')\n",
    "trainer_name = Path(model_base_path).name\n",
    "print(model_base_path, '\\n')\n",
    "print(trainer_name, '\\n')\n",
    "\n",
    "folds = (0, 1, 2, 3, 4)\n",
    "mixed_precision = None\n",
    "checkpoint_name = \"model_best\"\n",
    "\n",
    "trainer, params = load_model_and_checkpoint_files(str(model_base_path), folds, mixed_precision=mixed_precision,\n",
    "                                                  checkpoint_name=checkpoint_name)\n",
    "norm = norm_01 # z_norm # Select the right input normalization here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79129b0e-3c4e-4605-a31a-8bfb4ccd5e64",
   "metadata": {},
   "source": [
    "# Configs and prep\n",
    "### CHANGE YOUR PATHS AND CONFIGURATIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feeaa7a3-7301-4ca0-9644-5c12b301509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output folder name well, this is where we will store the WSI inference files\n",
    "output_folder = Path('example_output_folder')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# We now make the config and file yamls dynamically\n",
    "yml_output_folder = os.path.join(output_folder, 'example_files_and_config_ymls')\n",
    "os.makedirs(yml_output_folder, exist_ok=True)\n",
    "files_yml_output_filename = \"wsi_borderless_inference_files.yml\"\n",
    "config_yml_output_filename = \"wsi_borderless_inference_config.yml\"\n",
    "files_yml_output_path = os.path.join(yml_output_folder, files_yml_output_filename)\n",
    "config_yml_output_path = os.path.join(yml_output_folder, config_yml_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76632770-0647-4cf0-b453-da7e28244137",
   "metadata": {},
   "source": [
    "### Make files yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8de7466-3396-4ab9-89b1-13e3f5137323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All image files were matched\n",
      "Each matched image file has a single match\n",
      "\n",
      "\n",
      "CREATED FILES YAML: example_output_folder\\configs\\wsi_borderless_inference_files.yml\n"
     ]
    }
   ],
   "source": [
    "# Enter the folder with the images/wsi and the tissue/bg masks here. On top of this notebook you can download 2 example files, enter the images and tissue-mask folders below\n",
    "wsibulk_folder = \"/your/path/to/wsibulk\"\n",
    "TIGER_test_wsi = os.path.join(wsibulk_folder, 'images')\n",
    "TIGER_test_bg = os.path.join(wsibulk_folder, 'tissue-masks')\n",
    "image_anno_TIGER = find_matches(TIGER_test_wsi, TIGER_test_bg)\n",
    "\n",
    "matches = image_anno_TIGER # this should be a list of tuples with paths from wsi, mask matches: [(wsi_path1, mask_path1), (wsi_path2, mask_path2)]\n",
    "matches = make_files_yml_and_return_matches_to_run(matches, files_yml_output_path, output_folder) # this will remove files from the yaml that are currently beint processed or are processed already"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9033d-fcca-4f90-8d7a-e29e3183cddb",
   "metadata": {},
   "source": [
    "### Make config yaml\n",
    "This one is filled in already for the example model that comes with the repo. But you may need to adjust these settings for your own models. One thing you need to check though is whether you need to copy the data to a local drive (for example when its stored on a network drive). In this case you need to set copy_data to true and specify the copy_path.\n",
    "\n",
    "One more note: decrease the sampler_patch_size to reduce cpu usage, which may cause the dataloader to hang (this was the case in our Grand Challenge submission for the TIGER challenge, where we reduced it all the way to 1280 (2.5*model_patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46324975",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = True\n",
    "if copy_data == True:\n",
    "    copy_path = '/home/user/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "361c6c7f-350c-4923-8e56-f7318bee0192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto configuring CONFIG YAML. Replacing template placeholders:\n",
      "\t 'auto_files_yml' example_output_folder\\configs\\wsi_borderless_inference_files.yml\n",
      "\t 'auto_sampler_patch_size' 1280\n",
      "\t 'auto_spacing' 0.5\n",
      "\t 'auto_tissue_mask_spacing' 0.5\n",
      "\t 'auto_tissue_mask_ratio' 1.0\n",
      "\t 'auto_output_patch_size' 768\n",
      "CREATED CONFIG YAML: wsi_borderless_inference_config.yml\n"
     ]
    }
   ],
   "source": [
    "# Added hints for construction of config file if you want to do it yourself\n",
    "spacing = 0.5 # spacing for batch_shape spacing and annotation_parser output_spacing (leave its processing spacing on 4 or higher)\n",
    "\n",
    "model_patch_size = 512 # input size of model (should be square)\n",
    "half_model_patch_size=int(model_patch_size/2)\n",
    "\n",
    "sampler_patch_size = 1280 #4096 # use this as batch shape (= 8 * model_patch_size) \n",
    "assert sampler_patch_size % (model_patch_size/2) == 0 # needed for correct half overlap\n",
    "\n",
    "# due to half overlap there is half the model patch size without overlap on all 4 sides of the sampled patch\n",
    "output_patch_size = sampler_patch_size - 2 * half_model_patch_size # use this as your annotation_parser shape\n",
    "# Note that for this approach we need a CenterPointSampler, and center: True in the patch_sampler and patch_label_sampler\n",
    "\n",
    "tissue_mask_spacing = get_closest_spacing(WholeSlideImage(matches[0][1], backend='asap').spacings[0]) #this takes the first match's mask file, and takes its most detailed spacing\n",
    "tissue_mask_ratio = tissue_mask_spacing/spacing\n",
    "\n",
    "\n",
    "template = str(Path('tiger_example_iterator_templates/WSI_inference_config_remote_data_template.yml')) if copy_data == True else str(Path('tiger_example_iterator_templates/WSI_inference_config_local_data_template.yml'))\n",
    "\n",
    "with open(template) as f:\n",
    "    config_yml_str = str(yaml.safe_load(f))\n",
    "\n",
    "replace_dict = {\n",
    "    \"'auto_files_yml'\" : files_yml_output_path,\n",
    "    \"'auto_sampler_patch_size'\" : sampler_patch_size,\n",
    "    \"'auto_spacing'\" : spacing,\n",
    "    \"'auto_tissue_mask_spacing'\" : tissue_mask_spacing,\n",
    "    \"'auto_tissue_mask_ratio'\" : tissue_mask_ratio,\n",
    "    \"'auto_output_patch_size'\" : output_patch_size\n",
    "}\n",
    "\n",
    "print('\\nAuto configuring CONFIG YAML. Replacing template placeholders:')\n",
    "for k, v in replace_dict.items():\n",
    "    print('\\t', k, v)\n",
    "    config_yml_str = config_yml_str.replace(k, str(v))\n",
    "\n",
    "config_yml = yaml.safe_load(config_yml_str)\n",
    "\n",
    "with open(config_yml_output_path, 'w') as f:\n",
    "    yaml.dump(config_yml, f)\n",
    "    print('CREATED CONFIG YAML:', config_yml_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99c6c8-abbf-4238-bbca-f00f2fe35410",
   "metadata": {},
   "source": [
    "#### Some variable settings you can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26d3ccdc-3e0e-4bc3-a86b-317ad2a1a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"validation\"\n",
    "context = 'spawn' if os.name == \"nt\" else 'fork'\n",
    "image_path = None\n",
    "previous_file_key = None\n",
    "files_exist_already = None  # not sure if needed\n",
    "plot = False\n",
    "# following is later used to check if we can remove big empty parts of the sampled patch before inference\n",
    "sampler_patch_size_range = list(range(sampler_patch_size))\n",
    "half_patch_size_start_idxs = sampler_patch_size_range[0::half_model_patch_size]\n",
    "half_patch_size_end_idxs = [idx + half_model_patch_size for idx in half_patch_size_start_idxs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a05eac-0c5c-45c5-a0b2-828ad80a6bc6",
   "metadata": {},
   "source": [
    "# Run\n",
    "The loop could be simplified quite a bit, we'll release an improved version in our v2 code release!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c707e2af-b796-46b6-b517-1177343b411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iterator = create_batch_iterator(mode=mode,\n",
    "                                          context=context,\n",
    "                                          user_config=config_yml_output_path,\n",
    "                                          presets=('slidingwindow',),\n",
    "                                          cpus=4,\n",
    "                                          number_of_batches=-1,\n",
    "                                          return_info=True)\n",
    "\n",
    "for x_batch, y_batch, info in tqdm(training_iterator):\n",
    "    ### Get image data, check if new image, save previous image if there was one, if new image create new image file\n",
    "    sample_reference = info['sample_references'][0]['reference']\n",
    "    current_file_key = sample_reference.file_key\n",
    "    if current_file_key != previous_file_key:  # if starting a new image\n",
    "        if previous_file_key != None and files_exist_already != True:  # if there was a previous image, and the previous image did not exist already (can also be None)\n",
    "            wsm_writer.save()  # save previous mask\n",
    "            wsu_writer.save()  # save previous uncertainty\n",
    "            # Save runtime\n",
    "            end_time = time.time()\n",
    "            run_time = end_time - start_time\n",
    "            text_file = open(output_folder / (image_path.stem + '_runtime.txt'), \"w\")\n",
    "            text_file.write(str(run_time))\n",
    "            text_file.close()\n",
    "        # Getting file settings and path, doing check if exists already\n",
    "        with training_iterator.dataset.get_wsi_from_reference(sample_reference) as wsi:\n",
    "            image_path = wsi.path\n",
    "            shape = wsi.shapes[wsi.get_level_from_spacing(spacing)]\n",
    "            real_spacing = wsi.get_real_spacing(spacing)\n",
    "        wsm_path = output_folder / (image_path.stem + '_nnunet.tif')\n",
    "        wsu_path = output_folder / (image_path.stem + '_uncertainty.tif')\n",
    "        if os.path.isfile(wsm_path) and os.path.isfile(wsu_path):\n",
    "            files_exist_already = True  # this means we can skip this whole loop for this file key, checked above '### Prep, predict and uncertainty'\n",
    "            previous_file_key = current_file_key\n",
    "            print(f'[SKIPPING] files for {image_path.stem} exist already')\n",
    "            continue  # continue to next batch\n",
    "        else:\n",
    "            files_exist_already = False\n",
    "        # Create new writer and file\n",
    "        start_time = time.time()\n",
    "        wsm_writer = WholeSlideMaskWriter()  # whole slide mask\n",
    "        wsu_writer = WholeSlideMaskWriter()  # whole slide uncertainty\n",
    "        # Create files\n",
    "        wsm_writer.write(path=wsm_path, spacing=real_spacing, dimensions=shape,\n",
    "                         tile_shape=(output_patch_size, output_patch_size))\n",
    "        wsu_writer.write(path=wsu_path, spacing=real_spacing,\n",
    "                         dimensions=shape, tile_shape=(output_patch_size, output_patch_size))\n",
    "\n",
    "    ### If this file already exists, skip\n",
    "    if files_exist_already:\n",
    "        continue\n",
    "\n",
    "    ### Trim check\n",
    "    trim_top_idx, trim_bottom_idx, trim_left_idx, trim_right_idx = get_trim_indexes(y_batch)\n",
    "    x_batch_maybe_trimmed = x_batch[:, trim_top_idx : trim_bottom_idx, trim_left_idx: trim_right_idx, :]\n",
    "\n",
    "    ### Prep, predict and uncertainty\n",
    "    prep = norm(x_batch_maybe_trimmed)\n",
    "\n",
    "    softmax_list = ensemble_softmax_list(trainer, params, prep)\n",
    "    softmax_mean = np.array(softmax_list).mean(0)\n",
    "    pred_output_maybe_trimmed = softmax_mean.argmax(axis=-1)\n",
    "\n",
    "    uncertainty = softmax_list_and_mean_to_uncertainty(softmax_list, softmax_mean)\n",
    "    uncertainty_output_maybe_trimmed = np.array((uncertainty.clip(0, 4) / 4 * 255).int()) \n",
    "\n",
    "    ### Reconstruct possible trim\n",
    "    pred_output = np.zeros((sampler_patch_size, sampler_patch_size))\n",
    "    pred_output[trim_top_idx : trim_bottom_idx, trim_left_idx: trim_right_idx] = pred_output_maybe_trimmed\n",
    "\n",
    "    uncertainty_output = np.zeros((sampler_patch_size, sampler_patch_size))\n",
    "    uncertainty_output[trim_top_idx: trim_bottom_idx, trim_left_idx: trim_right_idx] = uncertainty_output_maybe_trimmed\n",
    "\n",
    "    # Only write inner part\n",
    "    pred_output_inner = fit_data(pred_output, [output_patch_size, output_patch_size])\n",
    "    uncertainty_output_inner = fit_data(uncertainty_output, [output_patch_size, output_patch_size])\n",
    "    y_batch_inner = fit_data(y_batch[0], [output_patch_size, output_patch_size]).astype('int64')\n",
    "    \n",
    "    ### Get patch point\n",
    "    point = info['sample_references'][0]['point']\n",
    "    c, r = point.x - output_patch_size/2, point.y - output_patch_size/2 # from middle point to upper left point of tile to write\n",
    "    \n",
    "    ### Write tile and set previous file key for next loop check\n",
    "    wsm_writer.write_tile(tile=pred_output_inner, coordinates=(int(c), int(r)), mask=y_batch_inner)\n",
    "    wsu_writer.write_tile(tile=uncertainty_output_inner, coordinates=(int(c), int(r)), mask=y_batch_inner)\n",
    "    previous_file_key = current_file_key\n",
    "\n",
    "wsm_writer.save()  # if done save last image\n",
    "wsu_writer.save()  # if done save last image\n",
    "\n",
    "# Save runtime\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "text_file = open(output_folder / (image_path.stem + '_runtime.txt'), \"w\")\n",
    "text_file.write(str(run_time))\n",
    "text_file.close()\n",
    "\n",
    "training_iterator.stop()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15032f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
